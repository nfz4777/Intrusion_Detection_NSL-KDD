{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0920dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy, kl_divergence\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "# processing imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold,GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score,recall_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d19a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = (['duration'\n",
    ",'protocol_type'\n",
    ",'service'\n",
    ",'flag'\n",
    ",'src_bytes'\n",
    ",'dst_bytes'\n",
    ",'land'\n",
    ",'wrong_fragment'\n",
    ",'urgent'\n",
    ",'hot'\n",
    ",'num_failed_logins'\n",
    ",'logged_in'\n",
    ",'num_compromised'\n",
    ",'root_shell'\n",
    ",'su_attempted'\n",
    ",'num_root'\n",
    ",'num_file_creations'\n",
    ",'num_shells'\n",
    ",'num_access_files'\n",
    ",'num_outbound_cmds'\n",
    ",'is_host_login'\n",
    ",'is_guest_login'\n",
    ",'count'\n",
    ",'srv_count'\n",
    ",'serror_rate'\n",
    ",'srv_serror_rate'\n",
    ",'rerror_rate'\n",
    ",'srv_rerror_rate'\n",
    ",'same_srv_rate'\n",
    ",'diff_srv_rate'\n",
    ",'srv_diff_host_rate'\n",
    ",'dst_host_count'\n",
    ",'dst_host_srv_count'\n",
    ",'dst_host_same_srv_rate'\n",
    ",'dst_host_diff_srv_rate'\n",
    ",'dst_host_same_src_port_rate'\n",
    ",'dst_host_srv_diff_host_rate'\n",
    ",'dst_host_serror_rate'\n",
    ",'dst_host_srv_serror_rate'\n",
    ",'dst_host_rerror_rate'\n",
    ",'dst_host_srv_rerror_rate'\n",
    ",'attack'\n",
    ",'difficulty_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0cf47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(df):\n",
    "    df_malicious = df[df['binary_attack'] == 1]\n",
    "    df_benign= df[df['binary_attack'] == 0]\n",
    "    \n",
    "    print('Before subsampling: ', df_benign.shape, df_malicious.shape)\n",
    "    \n",
    "    df_benign = df_benign.sample(len(df_malicious), random_state = 0)\n",
    "    df = pd.concat([df_malicious, df_benign])\n",
    "    df = df.sample(frac=1, random_state=0)\n",
    "    \n",
    "    print('After subsampling: ', df_benign.shape, df_malicious.shape)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823aec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(x1, y1):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    X_t = tsne.fit_transform(x1)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(X_t[np.where(y1 == 0), 0], X_t[np.where(y1 == 0), 1], marker='o', color='g', linewidth='1', alpha=0.8, label=0)\n",
    "    plt.scatter(X_t[np.where(y1 == 1), 0], X_t[np.where(y1 == 1), 1], marker='o', color='r', linewidth='1', alpha=0.8, label=1)\n",
    "\n",
    "    plt.legend(loc='best');\n",
    "    #plt.savefig(name);\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e090248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_heatmap(y_pred):\n",
    "    \n",
    "    # overall accuracy \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print( f'Overall Accuracy: {acc*100:.2f}%' )\n",
    "    print(\"--------------------------\")    \n",
    "    \n",
    "    # report\n",
    "    print(classification_report(y, y_pred))\n",
    "    figsize=(8,5)\n",
    "    #y_pred = y_pred.astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=np.unique(y_test))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_test), columns=np.unique(y_test))\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c65270ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('kdd_train.txt',header=None,names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d3a2915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 43)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc89d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
       "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
       "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
       "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
       "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
       "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
       "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
       "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
       "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "       'dst_host_srv_rerror_rate', 'attack', 'difficulty_level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accessing names of training columns\n",
    "lst_names = df_train.columns\n",
    "lst_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc0dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will make the attack column binomial by classifying all attacks as one i.e. normal flow vs attack\n",
    "df_train[\"binary_attack\"]=df_train.attack.map(lambda a: 0 if a == 'normal' else 1)\n",
    "df_train.drop('attack',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b333f19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    67343\n",
       "1    58630\n",
       "Name: binary_attack, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['binary_attack'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd1af171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encoding\n",
    "def one_hot(df, cols):\n",
    "    \"\"\"\n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode\n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(each, 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91789a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protocol_type', 'service', 'flag']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining col list\n",
    "cols = ['protocol_type','service','flag']\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d85458f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12403\\AppData\\Local\\Temp\\ipykernel_8988\\445847675.py:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(each, 1)\n",
      "C:\\Users\\12403\\AppData\\Local\\Temp\\ipykernel_8988\\445847675.py:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(each, 1)\n",
      "C:\\Users\\12403\\AppData\\Local\\Temp\\ipykernel_8988\\445847675.py:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(each, 1)\n"
     ]
    }
   ],
   "source": [
    "df=one_hot(df_train,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a2c95f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8142da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('difficulty_level',axis = 1,inplace = True)\n",
    "#Train Data\n",
    "\n",
    "df.drop('num_outbound_cmds',axis = 1,inplace = True)\n",
    "df.drop('num_root',axis = 1,inplace = True)\n",
    "\n",
    "#This variable is highly correlated with serror_rate and should be ignored for analysis.\n",
    "#(Correlation = 0.9983615072725952)\n",
    "df.drop('srv_serror_rate',axis = 1,inplace = True)\n",
    "\n",
    "#This variable is highly correlated with rerror_rate and should be ignored for analysis.\n",
    "#(Corredfation = 0.9947309539817937)\n",
    "df.drop('srv_rerror_rate',axis = 1, inplace=True)\n",
    "\n",
    "#This variable is highly correlated with srv_serror_rate and should be ignored for analysis.\n",
    "#(Correlation = 0.9993041091850098)\n",
    "df.drop('dst_host_srv_serror_rate',axis = 1, inplace=True)\n",
    "\n",
    "#This variable is highly correlated with rerror_rate and should be ignored for analysis.\n",
    "#(Correlation = 0.9869947924956001)\n",
    "df.drop('dst_host_serror_rate',axis = 1, inplace=True)\n",
    "\n",
    "#This variable is highly correlated with srv_rerror_rate and should be ignored for analysis.\n",
    "#(Correlation = 0.9821663427308375)\n",
    "df.drop('dst_host_rerror_rate',axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03cc753d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 116)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0bc8486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before subsampling:  (67343, 116) (58630, 116)\n",
      "After subsampling:  (58630, 116) (58630, 116)\n"
     ]
    }
   ],
   "source": [
    "original_df=subsample(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cf65947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12403\\AppData\\Local\\Temp\\ipykernel_8988\\435235637.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = normal.append(anomaly).sample(frac=1).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "normal = original_df[original_df['binary_attack'] == 0].sample(3000)\n",
    "anomaly = original_df[original_df['binary_attack'] == 1].sample(3000)\n",
    "\n",
    "df = normal.append(anomaly).sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e638b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['binary_attack'], axis = 1).values\n",
    "Y = df[\"binary_attack\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fc1eb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 115)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b68ce16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import regularizers\n",
    "## input layer \n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "\n",
    "## encoding part\n",
    "encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoded = Dense(50, activation='relu')(encoded)\n",
    "\n",
    "## decoding part\n",
    "decoded = Dense(50, activation='tanh')(encoded)\n",
    "decoded = Dense(100, activation='tanh')(decoded)\n",
    "\n",
    "## output layer\n",
    "output_layer = Dense(X.shape[1], activation='relu')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b236c8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edd44fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdc23bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = original_df.drop([\"binary_attack\"], axis=1)\n",
    "y = original_df[\"binary_attack\"].values\n",
    "\n",
    "x_scale = preprocessing.MinMaxScaler().fit_transform(x.values)\n",
    "x_norm, x_anomaly = x_scale[y == 0], x_scale[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6149d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117260, 115)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0933cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58630, 115)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e4f3956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1s 237us/sample - loss: 0.0365 - val_loss: 0.0187\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 0s 26us/sample - loss: 0.0145 - val_loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12403\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 0s 25us/sample - loss: 0.0090 - val_loss: 0.0075\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 0s 25us/sample - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 0s 25us/sample - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 0s 25us/sample - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 0s 24us/sample - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 0s 24us/sample - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 0s 25us/sample - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 0s 24us/sample - loss: 0.0032 - val_loss: 0.0032\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_norm[0:5000], x_norm[0:5000], \n",
    "                batch_size = 256, epochs = 10, \n",
    "                shuffle = True, validation_split = 0.20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00b5a27",
   "metadata": {},
   "source": [
    "I am going to obtain the latent repreentation of the autoencoders for the dimentionality reduction.\n",
    "\n",
    "It will reduce the dimentionality from 115 to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee1a1e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_representation = Sequential()\n",
    "latent_representation.add(autoencoder.layers[0])\n",
    "latent_representation.add(autoencoder.layers[1])\n",
    "latent_representation.add(autoencoder.layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9433f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12403\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "norm_hid_rep = latent_representation.predict(x_norm[:10000])\n",
    "anomaly_hid_rep = latent_representation.predict(x_anomaly[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4074311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_hid_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7bfe836",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_x = np.append(norm_hid_rep, anomaly_hid_rep, axis = 0)\n",
    "y_n = np.zeros(norm_hid_rep.shape[0])\n",
    "y_a = np.ones(anomaly_hid_rep.shape[0])\n",
    "rep_y = np.append(y_n, y_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4a7679d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 50)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6516a087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ade1ca32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.97      2544\n",
      "         1.0       0.98      0.97      0.97      2456\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.97      0.97      0.97      5000\n",
      "weighted avg       0.97      0.97      0.97      5000\n",
      "\n",
      "\n",
      "Accuracy Score:  0.972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.25)\n",
    "clf = LogisticRegression(solver=\"lbfgs\").fit(train_x, train_y)\n",
    "pred_y = clf.predict(val_x)\n",
    "\n",
    "print (\"\")\n",
    "print (\"Classification Report: \")\n",
    "print (classification_report(val_y, pred_y))\n",
    "\n",
    "print (\"\")\n",
    "print (\"Accuracy Score: \", accuracy_score(val_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab398ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9b85e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
